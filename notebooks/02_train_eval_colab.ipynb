{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "02_train_eval_colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train + Evaluate Retrieval in Colab\n",
        "\n",
        "This notebook continues after tokenization.\n",
        "\n",
        "Pipeline in this notebook:\n",
        "1. Clone/update repo and install dependencies\n",
        "2. Check token/split files\n",
        "3. Train contrastive embedder\n",
        "4. Evaluate `Recall@1/10/100`, `MRR`\n",
        "5. Save artifacts to Google Drive (optional)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Runtime\n",
        "\n",
        "In Colab: `Runtime -> Change runtime type -> GPU`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import platform\n",
        "print('Python:', platform.python_version())\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    print('Torch:', torch.__version__)\n",
        "    print('CUDA available:', torch.cuda.is_available())\n",
        "    if torch.cuda.is_available():\n",
        "        print('GPU:', torch.cuda.get_device_name(0))\n",
        "except Exception as exc:\n",
        "    print('Torch check failed:', exc)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Clone/update repo and switch into it\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "REPO_ROOT = Path('/content/CL_ml')\n",
        "if not REPO_ROOT.exists():\n",
        "    !git clone https://github.com/epitaph76/CL_ml.git /content/CL_ml\n",
        "else:\n",
        "    print('Repo already exists at', REPO_ROOT)\n",
        "\n",
        "subprocess.run(['git', '-C', str(REPO_ROOT), 'pull', '--ff-only'], check=False)\n",
        "head = subprocess.check_output(['git', '-C', str(REPO_ROOT), 'rev-parse', '--short', 'HEAD'], text=True).strip()\n",
        "print('Repo HEAD:', head)\n",
        "%cd /content/CL_ml\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Install project dependencies\n",
        "!pip -q install -r /content/CL_ml/requirements.txt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Data paths and quick checks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "REPO_ROOT = Path('/content/CL_ml')\n",
        "TOKENS_ROOT = REPO_ROOT / 'data' / 'tokens'\n",
        "SPLITS_ROOT = REPO_ROOT / 'data' / 'splits'\n",
        "CHECKPOINTS_ROOT = REPO_ROOT / 'data' / 'checkpoints'\n",
        "REPORTS_ROOT = REPO_ROOT / 'data' / 'reports'\n",
        "\n",
        "TOKENS_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "SPLITS_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "CHECKPOINTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "REPORTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print('TOKENS_ROOT =', TOKENS_ROOT)\n",
        "print('SPLITS_ROOT =', SPLITS_ROOT)\n",
        "print('CHECKPOINTS_ROOT =', CHECKPOINTS_ROOT)\n",
        "print('REPORTS_ROOT =', REPORTS_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: mount Google Drive and point TOKENS_ROOT to your prepared tokens\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# TOKENS_ROOT = Path('/content/drive/MyDrive/CL_ml_tokens')\n",
        "# print('TOKENS_ROOT switched to', TOKENS_ROOT)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Validate tokens\n",
        "import itertools\n",
        "\n",
        "token_files = sorted(TOKENS_ROOT.rglob('*.pt')) + sorted(TOKENS_ROOT.rglob('*.npz'))\n",
        "print('Token files found:', len(token_files))\n",
        "for p in itertools.islice(token_files, 10):\n",
        "    print('-', p)\n",
        "\n",
        "if len(token_files) < 3:\n",
        "    raise RuntimeError(\n",
        "        'Need at least 3 token files. Run notebook 01_moss_tokenization_colab.ipynb or copy tokens to TOKENS_ROOT.'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Build splits if missing\n",
        "import shlex\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "need_splits = not all((SPLITS_ROOT / name).exists() for name in ['train.txt', 'val.txt', 'test.txt'])\n",
        "if need_splits:\n",
        "    cmd = [\n",
        "        'python', '-m', 'src.dataset.build_splits',\n",
        "        '--tokens-root', str(TOKENS_ROOT),\n",
        "        '--output-root', str(SPLITS_ROOT),\n",
        "        '--val-ratio', '0.1',\n",
        "        '--test-ratio', '0.1',\n",
        "    ]\n",
        "    print('Running:', ' '.join(shlex.quote(x) for x in cmd))\n",
        "    env = os.environ.copy()\n",
        "    env['PYTHONPATH'] = str(REPO_ROOT) + (':' + env['PYTHONPATH'] if env.get('PYTHONPATH') else '')\n",
        "    subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, check=True)\n",
        "else:\n",
        "    print('Splits already exist, skip build.')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Inspect split summary\n",
        "for name in ['train.txt', 'val.txt', 'test.txt', 'summary.json']:\n",
        "    p = SPLITS_ROOT / name\n",
        "    print('\n",
        "===', name, '===')\n",
        "    if p.exists():\n",
        "        print(p.read_text(encoding='utf-8')[:500])\n",
        "    else:\n",
        "        print('not found')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Train baseline embedder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Full training run\n",
        "import shlex\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "cmd = [\n",
        "    'python', '-m', 'src.train.train_contrastive',\n",
        "    '--config', 'configs/train.yaml',\n",
        "    '--device', 'auto',\n",
        "    '--output-dir', str(CHECKPOINTS_ROOT),\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(x) for x in cmd))\n",
        "env = os.environ.copy()\n",
        "env['PYTHONPATH'] = str(REPO_ROOT) + (':' + env['PYTHONPATH'] if env.get('PYTHONPATH') else '')\n",
        "subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Smoke training run (uncomment if needed)\n",
        "# import shlex, subprocess, os\n",
        "# cmd = [\n",
        "#     'python', '-m', 'src.train.train_contrastive',\n",
        "#     '--config', 'configs/train.yaml',\n",
        "#     '--device', 'auto',\n",
        "#     '--max-steps-per-epoch', '5',\n",
        "#     '--output-dir', str(REPO_ROOT / 'data' / 'checkpoints_smoke'),\n",
        "# ]\n",
        "# print('Running:', ' '.join(shlex.quote(x) for x in cmd))\n",
        "# env = os.environ.copy()\n",
        "# env['PYTHONPATH'] = str(REPO_ROOT) + (':' + env['PYTHONPATH'] if env.get('PYTHONPATH') else '')\n",
        "# subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Check checkpoint files\n",
        "for name in ['best.pt', 'last.pt', 'history.json']:\n",
        "    p = CHECKPOINTS_ROOT / name\n",
        "    print(name, '->', 'exists' if p.exists() else 'missing', p)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Evaluate retrieval metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Exact retrieval metrics\n",
        "import shlex\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "cmd = [\n",
        "    'python', '-m', 'src.index.evaluate_retrieval',\n",
        "    '--config', 'configs/train.yaml',\n",
        "    '--checkpoint', str(CHECKPOINTS_ROOT / 'best.pt'),\n",
        "    '--tokens-root', str(TOKENS_ROOT),\n",
        "    '--splits-root', str(SPLITS_ROOT),\n",
        "    '--split', 'val',\n",
        "    '--topk', '1,10,100',\n",
        "    '--device', 'auto',\n",
        "    '--output-json', str(REPORTS_ROOT / 'val_exact.json'),\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(x) for x in cmd))\n",
        "env = os.environ.copy()\n",
        "env['PYTHONPATH'] = str(REPO_ROOT) + (':' + env['PYTHONPATH'] if env.get('PYTHONPATH') else '')\n",
        "subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Exact + FAISS metrics (optional)\n",
        "import shlex\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "cmd = [\n",
        "    'python', '-m', 'src.index.evaluate_retrieval',\n",
        "    '--config', 'configs/train.yaml',\n",
        "    '--checkpoint', str(CHECKPOINTS_ROOT / 'best.pt'),\n",
        "    '--tokens-root', str(TOKENS_ROOT),\n",
        "    '--splits-root', str(SPLITS_ROOT),\n",
        "    '--split', 'val',\n",
        "    '--topk', '1,10,100',\n",
        "    '--device', 'auto',\n",
        "    '--use-faiss',\n",
        "    '--output-json', str(REPORTS_ROOT / 'val_exact_faiss.json'),\n",
        "]\n",
        "print('Running:', ' '.join(shlex.quote(x) for x in cmd))\n",
        "env = os.environ.copy()\n",
        "env['PYTHONPATH'] = str(REPO_ROOT) + (':' + env['PYTHONPATH'] if env.get('PYTHONPATH') else '')\n",
        "subprocess.run(cmd, cwd=str(REPO_ROOT), env=env, check=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Print metric JSON files\n",
        "import json\n",
        "\n",
        "for name in ['val_exact.json', 'val_exact_faiss.json']:\n",
        "    p = REPORTS_ROOT / name\n",
        "    print('\n",
        "===', name, '===')\n",
        "    if p.exists():\n",
        "        payload = json.loads(p.read_text(encoding='utf-8'))\n",
        "        print(json.dumps(payload.get('results', {}), indent=2, ensure_ascii=False))\n",
        "    else:\n",
        "        print('not found')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Save artifacts to Google Drive (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Optional: persist run artifacts\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# !mkdir -p /content/drive/MyDrive/CL_ml_runs/run1\n",
        "# !cp -r /content/CL_ml/data/checkpoints /content/drive/MyDrive/CL_ml_runs/run1/\n",
        "# !cp -r /content/CL_ml/data/reports /content/drive/MyDrive/CL_ml_runs/run1/\n",
        "# !cp -r /content/CL_ml/configs /content/drive/MyDrive/CL_ml_runs/run1/\n"
      ]
    }
  ]
}